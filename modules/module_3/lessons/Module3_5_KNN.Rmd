---
title: "K-Nearest Neighbor"
author: "Ellen Bledsoe"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Prediction, Machine Learning

Now, we're going to work through an example of machine learning, which is used in a variety of ways in data science - and across industries and discplines.

The goal here is that we have \~ 50 unlabeled collars, and we want to be able to predict who made them. Remember that Budget Collars LLC provided us with collars that are failing, which is a risk to human life! So we need to throw out any collars that we think were made by this company, and only incorporate new collars from our unlabeled batch that we think were made by Collarium Inc.

### What is machine learning? Group reading and discussion.

Take 10 minutes to read ![this article](https://medium.com/@randylaosat/a-beginners-guide-to-machine-learning-dfadc19f6caf).

I'll signal when 10 minutes is up. Get into your groups and discuss the following questions.\
1. What is machine learning? Is it different than AI?\
2. What types of general problems do machine learning techniques tackle?\
3. Given what you've read, what kind algorithm type might we employ for our problem?

## knn in R

K-nearest neighbors is a classification algorithm (e.g. it attempts to predict labels that are classes in R). We're going to work through a small example on our data set before attempting to build the full model.

### Check-in

What are our classes/labels here?

### Data cleaning and prepping, splitting and normalizing

First, we need to process our data a bit before we jump into our algorithm.

```{r}
# remind ourselves of what full contains
glimpse(full)


# First, we want to filter out the missing data - we'll run our full algorithm 
# on this later. 

# How should we filter?

collars_to_label = full %>%
  filter(is.na(maker))

full_filtered = full %>%
  filter(!is.na(maker))


# Next, let's get rid of some unneeded columns
filtered = full_filtered %>%
  dplyr::select(-collar_id, -fail,-antenna_length, -weight) %>% 
  mutate(maker = as.factor(maker))
```

### Check-in

Why are we doing this? We're keeping it to two variables here... later on we'll do more!

On to normalization.

```{r}

# custom function for normalizing
nor <-function(x){
  (x -min(x))/(max(x)-min(x))
}

knn_data <- filtered %>%
  mutate(battery_life_norm = scale(filtered$battery_life),
         signal_distance_norm = scale(filtered$signal_distance)) %>%
  dplyr::select(-battery_life, -signal_distance)

```

Let's plot a histogram of our normalized data

```{r}
knn_data %>% 
  summarise(mean_bat = mean(battery_life_norm),
            sd_bat = sd(battery_life_norm))

ggplot(knn_data, aes(battery_life_norm)) +
  geom_histogram()

ggplot(knn_data, aes(battery_life_norm, fill = maker)) +
  geom_histogram()
```


### Check-in

Why are we doing this? Can you think of a good reason why we have to normalize the values here? What does normalize mean?

### We have data that we're ready to put into our algorithm - but first we need

to figure out how the algorithm actually works.

We're going to watch a brief video: <https://www.youtube.com/watch?v=MDniRwXizWo>

After we're finished, get into your groups and discuss the following points:\
1. For our small, filtered data set with two variables, how would you draw a simple diagram like in the video that demonstrates how k-nn is working?\
2. Can you envision how this would work/what it would look like with more than two variables?\
3. What would happen if you increase or decrease K in the GoT example above, or generally?

## Let's try our hand at k-nn

```{r}
#loading package to do knn
#install.packages('class')
library(class)

#splitting the data up 
train <- knn_data %>% select(-maker)
class <- knn_data$maker

# select training data (70%)

training <- train[1:70,]
testing <- train[71:100,]

model_test = knn(train = training, test = testing, cl = class[1:70], k = 5, prob = TRUE)

# Let's plot our outcome. 

# We're going to use a complicated plotting function I built to inpsect things
# You don't need to understand the guts of this....
source("../scripts/knn_plot.R")

knn_plot(knn_data, mod = mod_test)

```

### Group discussion

Can you interpret this plot? Focus on a few points:\
1. What are the gridded points?\
2. What do the large points represent?\
3. What are the lines here?

### Final steps - making predictions

So we've gotten to a point where we have a model we think is good (let's go with k = 5). Let's use it on the test data we want to predict labels for!

```{r}
glimpse(collars_to_label)

# Getting ready to feed data in
collars_to_label_norm = collars_to_label %>%
  dplyr::select(battery_life, signal_distance) %>%
  mutate(battery_life_norm = nor(battery_life), 
         signal_distance_norm = nor(signal_distance)) %>%
  dplyr::select(battery_life_norm, signal_distance_norm)

mod = knn(train = train, test = collars_to_label_norm, cl = cl, k = 5)

collars_to_label %>%
  mutate(pred_class = mod)
```
